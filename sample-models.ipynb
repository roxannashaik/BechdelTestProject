{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, auc\n",
    "from sklearn.metrics import roc_curve, make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from matplotlib.legend_handler import HandlerLine2D \n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from vecstack import stacking\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(['ourselves', 'between', 'but', 'again','there', 'about', 'once', \\\n",
    "                 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an',\\\n",
    "                 'be', 'some', 'for', 'do', 'its', 'such', 'into', 'of', 'most', \n",
    "                 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from',\\\n",
    "                 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your',\\\n",
    "                 'through', 'don', 'nor', 'me', 'were', 'more',\\\n",
    "                 'this', 'down', 'should', 'our', 'their', 'while', 'above', \\\n",
    "                 'both', 'up', 'to', 'ours', 'had', 'all', 'no', 'when'\\\n",
    "                 , 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', \\\n",
    "                 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', \\\n",
    "                 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', \\\n",
    "                 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those'\\\n",
    "                 , 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against',\\\n",
    "                 'a', 'by', 'doing', 'it', 'how','b','the', 'you', 'further', 'href', \\\n",
    "                 'was', 'here', 'than','you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer={'accuracy': make_scorer(accuracy_score),\n",
    "        'f1_score': make_scorer(f1_score),\n",
    "        'precision': make_scorer(precision_score, pos_label=1, average='binary'),\n",
    "        'recall': make_scorer(recall_score), \n",
    "        'mean_squared_error': make_scorer(mean_squared_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(d.loc[:, 'text_info'],\\\n",
    "                                                       d.loc[:, 'bechdal_int'], test_size = 0.2)\n",
    "v2 = TfidfVectorizer(analyzer='word',use_idf=True, ngram_range=(2,2), \\\n",
    "                         token_pattern= r'\\w{1,}', stop_words=stopwords, sublinear_tf=True)\n",
    "train_X = v2.fit_transform(X_train)\n",
    "test_X = v2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "nb = MultinomialNB(alpha =0.1)\n",
    "rf = RandomForestClassifier(max_depth=4, random_state=0, n_estimators = 50)\n",
    "ab = AdaBoostClassifier(dTree, n_estimators =50)\n",
    "lr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "\n",
    "models = [dTree,nb,rf,ab,lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.66666667]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.50000000]\n",
      "    fold  3:  [0.71428571]\n",
      "    fold  4:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.68730159] + [0.17399606]\n",
      "    FULL:     [0.67500000]\n",
      "\n",
      "model  1:     [MultinomialNB]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.37500000]\n",
      "    fold  3:  [0.28571429]\n",
      "    fold  4:  [0.42857143]\n",
      "    ----\n",
      "    MEAN:     [0.44007937] + [0.10475289]\n",
      "    FULL:     [0.45000000]\n",
      "\n",
      "model  2:     [RandomForestClassifier]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n",
      "model  3:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.66666667]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.50000000]\n",
      "    fold  3:  [0.28571429]\n",
      "    fold  4:  [0.71428571]\n",
      "    ----\n",
      "    MEAN:     [0.54444444] + [0.15021610]\n",
      "    FULL:     [0.55000000]\n",
      "\n",
      "model  4:     [LogisticRegression]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r1_train, r1_test = stacking(models,train_X, y_train, test_X, regression=False, \\\n",
    "                           mode='oof_pred_bag', save_dir=None, metric=accuracy_score, \\\n",
    "                           n_folds=5, stratified=True,shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n",
      "model  1:     [LogisticRegression]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n",
      "model  2:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.66666667]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.50000000]\n",
      "    fold  3:  [0.00000000]\n",
      "    fold  4:  [0.71428571]\n",
      "    ----\n",
      "    MEAN:     [0.48730159] + [0.25533363]\n",
      "    FULL:     [0.50000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r1_train, r1_test = stacking(top_3_models,train_X, y_train, test_X, regression=False, \\\n",
    "                           mode='oof_pred_bag', save_dir=None, metric=accuracy_score, \\\n",
    "                           n_folds=5, stratified=True,shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = AdaBoostClassifier(dTree, n_estimators = 50)\n",
    "    \n",
    "model1 = model1.fit(r1_train, y_train)\n",
    "y_pred1 = model1.predict(r1_test)\n",
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_models  = [rf,lr,ab] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n",
      "model  1:     [LogisticRegression]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n",
      "model  2:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.66666667]\n",
      "    fold  1:  [0.66666667]\n",
      "    fold  2:  [0.50000000]\n",
      "    fold  3:  [0.00000000]\n",
      "    fold  4:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.56666667] + [0.32659863]\n",
      "    FULL:     [0.57500000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2_train, r2_test = stacking(top_3_models,train_X, y_train, test_X, regression=False, \\\n",
    "                           mode='oof_pred_bag', save_dir=None, metric=accuracy_score, \\\n",
    "                           n_folds=5, stratified=True,shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = AdaBoostClassifier(dTree, n_estimators = 50)\n",
    "    \n",
    "model2 = model2.fit(r2_train, y_train)\n",
    "y_pred2 = model2.predict(r2_test)\n",
    "accuracy_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_models  = [rf,nb,ab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.62500000]\n",
      "    fold  3:  [0.57142857]\n",
      "    fold  4:  [0.57142857]\n",
      "    ----\n",
      "    MEAN:     [0.57579365] + [0.02560677]\n",
      "    FULL:     [0.57500000]\n",
      "\n",
      "model  1:     [MultinomialNB]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.37500000]\n",
      "    fold  3:  [0.28571429]\n",
      "    fold  4:  [0.42857143]\n",
      "    ----\n",
      "    MEAN:     [0.44007937] + [0.10475289]\n",
      "    FULL:     [0.45000000]\n",
      "\n",
      "model  2:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.66666667]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.50000000]\n",
      "    fold  3:  [0.00000000]\n",
      "    fold  4:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.54444444] + [0.32279642]\n",
      "    FULL:     [0.55000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r3_train, r3_test = stacking(r_models,train_X, y_train, test_X, regression=False, \\\n",
    "                           mode='oof_pred_bag', save_dir=None, metric=accuracy_score, \\\n",
    "                           n_folds=5, stratified=True,shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454545454545453"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = AdaBoostClassifier(dTree, n_estimators = 50)\n",
    "    \n",
    "model3 = model3.fit(r3_train, y_train)\n",
    "y_pred3 = model3.predict(r3_test)\n",
    "accuracy_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_models  = [dTree,nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.66666667]\n",
      "    fold  1:  [0.66666667]\n",
      "    fold  2:  [0.50000000]\n",
      "    fold  3:  [0.00000000]\n",
      "    fold  4:  [0.71428571]\n",
      "    ----\n",
      "    MEAN:     [0.50952381] + [0.26496053]\n",
      "    FULL:     [0.52500000]\n",
      "\n",
      "model  1:     [MultinomialNB]\n",
      "    fold  0:  [0.55555556]\n",
      "    fold  1:  [0.55555556]\n",
      "    fold  2:  [0.37500000]\n",
      "    fold  3:  [0.28571429]\n",
      "    fold  4:  [0.42857143]\n",
      "    ----\n",
      "    MEAN:     [0.44007937] + [0.10475289]\n",
      "    FULL:     [0.45000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train2, test2 = stacking(two_models,train_X, y_train, test_X, regression=False, \\\n",
    "                           mode='oof_pred_bag', save_dir=None, metric=accuracy_score, \\\n",
    "                           n_folds=5, stratified=True,shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_model = dTree\n",
    "    \n",
    "simp_model = simp_model.fit(train2, y_train)\n",
    "y_pred_simp2 = simp_model.predict(test2)\n",
    "accuracy_score(y_test, y_pred_simp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
